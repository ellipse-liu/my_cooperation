{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9291bb2e-c9b4-4f71-9c6d-bf6d5e6578aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 imports\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import io\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import matplotlib.animation\n",
    "import math\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26ff2a0e-315e-4b60-8515-f739c09e7255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 runfile directories\n",
    "runfile_directory = 'Runfiles/'\n",
    "results_directory = 'Results/'\n",
    "template_file = 'template.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1eb5a622-a41f-4e5f-b951-9e2dbb9e9696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 parameter dict and template writing functions\n",
    "parameter_dict = {'*fname': ['Python/Results/'],\n",
    "                  '*steps': ['200'],\n",
    "                 '*reps': ['50'],\n",
    "                 'letter_grades' : ['true'],\n",
    "                  'prefix' : [\"adjusted_sweeps\"],\n",
    "                  'grading_error_alpha' : ['150.0'],\n",
    "                  'grading_error_beta' : ['150.0'],\n",
    "                  'divorce_constant' : ['100',  '50', '25', '10', '0'],\n",
    "                  'max_strikes' : ['3', '5', '7', '11', '13'],\n",
    "                  'num_agents' : ['60'],\n",
    "                  'agent_tolerance_alpha' : ['1.0' , '2.0'], # (1,1), else alpha < beta for tolerance, with a hard cap of 4 grades down, old: '1.', '2.', '3.0', '4.0', '5.0'\n",
    "                  'agent_tolerance_beta' : ['1.0', '7.0'], #old '1.', '3.', '5.', '7.0', '8.0', '10.0'\n",
    "                  'agent_effort_alpha' : ['5.0', '10.0'],\n",
    "                  'agent_effort_beta' : ['1.5', '3.0', '5.0'], # effort beta < effort alpha\n",
    "                  'agent_std_effort' : ['0.01', '0.05', '0.075', '0.1', '0.2'],\n",
    "                  'min_agents_per_group' : ['3'],\n",
    "                  'max_agents_per_group' : ['4'],\n",
    "                  'group_track_rate' : ['1'],\n",
    "                  'agent_track_rate' : ['5'],\n",
    "                  'group_write_directory' : ['Python/Group_data/'],\n",
    "                  'agent_write_directory' : ['Python/Agent_data/'],\n",
    "                 }\n",
    "\n",
    "def design_runfile(new_fname, parameter_dict=parameter_dict):\n",
    "    with open(template_file) as template:\n",
    "        template_lines = template.readlines()\n",
    "\n",
    "    parameter_dict['*fname'] = [parameter_dict['*fname'][0] + new_fname.strip('.txt')]\n",
    "    \n",
    "    with open(runfile_directory + new_fname, 'w+') as new_file:\n",
    "        for line in template_lines:\n",
    "            param = line.split()[0]\n",
    "            if param not in parameter_dict:\n",
    "                new_file.write(line)\n",
    "            else:\n",
    "                fixer_upper = line.strip('\\n').split()[:2]\n",
    "                new_line = ' '.join(fixer_upper + (parameter_dict[param])) + '\\n'\n",
    "                new_file.write(new_line)\n",
    "                \n",
    "def delete_old_files(agent_dir, group_dir):\n",
    "    agent_files = os.listdir(agent_dir)\n",
    "    group_files = os.listdir(group_dir)\n",
    "    for file_name in agent_files:\n",
    "        file_path = os.path.join(agent_dir, file_name)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)  # Remove the file or link\n",
    "        except Exception as e:\n",
    "            print(f'Failed to delete {file_path}. Reason: {e}')\n",
    "    for file_name in group_files:\n",
    "        file_path = os.path.join(group_dir, file_name)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)  # Remove the file or link\n",
    "        except Exception as e:\n",
    "            print(f'Failed to delete {file_path}. Reason: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88ab3136-1780-458c-88b0-2c03351e0296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 Create the run file\n",
    "# parameter_dict['letter_grades'] = ['true']\n",
    "# parameter_dict['*fname'] = ['Python/Results/']\n",
    "# parameter_dict['prefix'] = ['server_runs_true_60']\n",
    "# parameter_dict['group_write_directory'] = ['Python/true_60/Group_data/']\n",
    "# parameter_dict['agent_write_directory'] = ['Python/true_60/Agent_data/']\n",
    "# design_runfile('server_runs_true_60.txt', parameter_dict)\n",
    "\n",
    "# parameter_dict['num_agents'] = ['150']\n",
    "# parameter_dict['prefix'] = ['server_runs_true_150']\n",
    "# parameter_dict['group_write_directory'] = ['Python/true_150/Group_data/']\n",
    "# parameter_dict['agent_write_directory'] = ['Python/true_150/Agent_data/']\n",
    "# design_runfile('server_runs_true_150.txt', parameter_dict)\n",
    "\n",
    "# parameter_dict['num_agents'] = ['200']\n",
    "# parameter_dict['prefix'] = ['server_runs_true_200']\n",
    "# parameter_dict['group_write_directory'] = ['Python/true_200/Group_data/']\n",
    "# parameter_dict['agent_write_directory'] = ['Python/true_200/Agent_data/']\n",
    "# design_runfile('server_runs_true_200.txt', parameter_dict)\n",
    "\n",
    "# parameter_dict['letter_grades'] = ['false']\n",
    "# parameter_dict['*fname'] = ['Python/test/']\n",
    "# parameter_dict['prefix'] = ['server_runs_false_60']\n",
    "# parameter_dict['group_write_directory'] = ['Python/false_60/Group_data/']\n",
    "# parameter_dict['agent_write_directory'] = ['Python/false_60/Agent_data/']\n",
    "# design_runfile('server_runs_false_60.txt', parameter_dict)\n",
    "\n",
    "#parameter_dict['num_agents'] = ['150']\n",
    "#parameter_dict['prefix'] = ['server_runs_false_150']\n",
    "#parameter_dict['group_write_directory'] = ['Python/false_150/Group_data/']\n",
    "#parameter_dict['agent_write_directory'] = ['Python/false_150/Agent_data/']\n",
    "#design_runfile('server_runs_false_150.txt', parameter_dict)\n",
    "\n",
    "#parameter_dict['num_agents'] = ['200']\n",
    "#parameter_dict['prefix'] = ['server_runs_false_200']\n",
    "#parameter_dict['group_write_directory'] = ['Python/false_200/Group_data/']\n",
    "#parameter_dict['agent_write_directory'] = ['Python/false_200/Agent_data/']\n",
    "#design_runfile('server_runs_false_200.txt', parameter_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0e8c9a3-4153-4c2e-9a00-9f8d6db3cd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL NUKE OLD FILES\n",
    "delete_old_files(\"Agent_data/\", \"Group_data/\")\n",
    "delete_old_files(\"test/Agent_data/\", \"test/Group_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d2e69f5-0018-4831-9c07-8f3ed97d1043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 Agent and group analysis directories\n",
    "result_prefix = \"server_runs_false_60_\"\n",
    "agent_directory = \"false_60/Agent_data/\"\n",
    "agent_file_prefix = result_prefix + \"Agent-\"\n",
    "group_directory = \"false_60/Group_data/\"\n",
    "group_file_prefix = result_prefix + \"Group-\"\n",
    "\n",
    "# backup directories\n",
    "agent_backup_directory = f\"{result_prefix}backup/Agent_data\"\n",
    "group_backup_directory = f\"{result_prefix}backup/Group_data\"\n",
    "if not os.path.exists(result_prefix + \"backup\"):\n",
    "    os.mkdir(result_prefix + \"backup\")\n",
    "    os.mkdir(agent_backup_directory)\n",
    "    os.mkdir(group_backup_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70abda62-8048-4502-8419-d71db156ed3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 agent and group intake functions\n",
    "existing_runs = {}\n",
    "existing_run_tracker = 0\n",
    "\n",
    "def get_agent_results(agent_file_prefix, time_steps):\n",
    "    agent_dfs = {}\n",
    "    global existing_runs, existing_run_tracker # get the existing runs\n",
    "    for filename in os.listdir(agent_directory): # for each file in the os\n",
    "        file_path = os.path.join(agent_directory, filename)\n",
    "        # Check if it's a regular file (not a directory)\n",
    "        if os.path.isfile(file_path) and agent_file_prefix in file_path:\n",
    "            print(f\"Processing file {file_path}\", end='\\r')\n",
    "            temp = open(file_path, 'r')\n",
    "            read = temp.readlines()\n",
    "            temp_lines = [line for line in read if not line.startswith('#')] # get lines for reading pure dfs\n",
    "            i2h, h2i, seeds = get_headers(read) # get i2h, h2i, seeds in order\n",
    "            num_sections = len(temp_lines)//(time_steps+1)\n",
    "            df_set = {}\n",
    "            for i in range(num_sections): # for each RUN\n",
    "                filtered_csv_string = ''.join(temp_lines)\n",
    "                csv_io = io.StringIO(filtered_csv_string)\n",
    "                df = pd.read_csv(csv_io, skiprows = i*(time_steps+1), nrows = time_steps, comment=\"#\")\n",
    "                if i2h[i] not in existing_runs: # if header is not marked as a run\n",
    "                    existing_runs[i2h[i]] = existing_run_tracker\n",
    "                    existing_run_tracker += 1 # create an existing run\n",
    "                    if i not in df_set: # if run number is not in the dfset assigned to current agent\n",
    "                        df_set[i] = {seeds[i]:df} # df_set -> run -> rep #create a new dict with seed #\n",
    "                    else:\n",
    "                        df_set[i][seeds[i]] = df # otherwise add a rep to the thing in df\n",
    "                else:\n",
    "                    if existing_runs[i2h[i]] not in df_set:\n",
    "                        df_set[existing_runs[i2h[i]]] = {seeds[i]:df}\n",
    "                    else:\n",
    "                        df_set[existing_runs[i2h[i]]][seeds[i]] = df\n",
    "            agent_dfs[filename.strip(agent_file_prefix).strip(\".txt\")] = df_set\n",
    "            with open(f\"{group_backup_directory}/{file_name}.pkl\", 'w+') as file:\n",
    "                # TODO MAKE BACKUP FOR EACH AGENT FILE\n",
    "    return agent_dfs\n",
    "\n",
    "def get_group_results(group_file_prefix, time_steps):\n",
    "    group_dfs = {}\n",
    "\n",
    "    global existing_runs, existing_run_tracker\n",
    "    \n",
    "    for filename in os.listdir(group_directory):\n",
    "        file_path = os.path.join(group_directory, filename)\n",
    "        # Check if it's a regular file (not a directory)\n",
    "        if os.path.isfile(file_path) and group_file_prefix in file_path:\n",
    "            print(f\"Processing file {file_path}\", end='\\r')\n",
    "            temp = open(file_path, 'r')\n",
    "            read = temp.readlines()\n",
    "            temp_lines = [line for line in read if not line.startswith('#')]\n",
    "            i2h, h2i, seeds = get_headers(read)\n",
    "            num_sections = len(temp_lines)//(time_steps+1)\n",
    "            df_set = {}\n",
    "            for i in range(num_sections):\n",
    "                filtered_csv_string = ''.join(temp_lines)\n",
    "                csv_io = io.StringIO(filtered_csv_string)\n",
    "                df = pd.read_csv(csv_io, skiprows = i*(time_steps+1), nrows = time_steps, comment=\"#\")\n",
    "                if i2h[i] not in existing_runs:\n",
    "                    existing_runs[i2h[i]] = existing_run_tracker\n",
    "                    existing_run_tracker += 1\n",
    "                    if i not in df_set:\n",
    "                        df_set[i] = {seeds[i]:df}\n",
    "                    else:\n",
    "                        df_set[i][seeds[i]] = df\n",
    "                else:\n",
    "                    if existing_runs[i2h[i]] not in df_set:\n",
    "                        df_set[existing_runs[i2h[i]]] = {seeds[i]:df}\n",
    "                    else:\n",
    "                        df_set[existing_runs[i2h[i]]][seeds[i]] = df\n",
    "            group_dfs[filename.strip(group_file_prefix).strip(\".txt\")] = df_set\n",
    "    return group_dfs\n",
    "\n",
    "def get_headers(lines): #gets headers and sorts them in order to align runs i use seeds, a fixed order array in order to track which seed run[i] is on\n",
    "    header_dicts = {}\n",
    "    seeds = []\n",
    "    reading_headers = False\n",
    "    current_counter = 0\n",
    "    headed = \"\"\n",
    "    for line in lines:\n",
    "        if not reading_headers:\n",
    "            if line.startswith('#') and 'curr_seed' not in line:\n",
    "                reading_headers = True\n",
    "                headed += line.strip('\\n')\n",
    "        else:\n",
    "            if not line.startswith('#'):\n",
    "                reading_headers = False\n",
    "                header_dicts[current_counter] = headed\n",
    "                current_counter += 1\n",
    "                headed = \"\"\n",
    "            else:\n",
    "                if 'currseed' in line:\n",
    "                    seeds.append(line.strip('\\n').split(': ')[1])\n",
    "                else:\n",
    "                    headed += line.strip('\\n')\n",
    "    return header_dicts, {x:y for y,x in header_dicts.items()}, seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69e56d2d-0d57-4278-865f-d46315cd827d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file false_60/Agent_data/server_runs_false_60_Agent-104.txt\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 7 get agent and group dfs\n",
    "agent_dfs = get_agent_results(agent_file_prefix, 200)\n",
    "print(\"Fetched agents\")\n",
    "group_dfs = get_group_results(group_file_prefix, 200)\n",
    "print(\"Fetched groups\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf85e9b-42c5-4fb3-a5d2-2c5e20fd66e2",
   "metadata": {},
   "source": [
    "# Updated Visualizations\n",
    "## Brainstorming\n",
    "What kind of visualization would be good?\n",
    "\n",
    "For starters, let's try re-creating the GUI of the experiment in a function and matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe10f21b-e0fb-4bcb-b7fd-f2b32afcb477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for visualizing the grades of each group growing up and down\n",
    "def isnan(value):\n",
    "    if isinstance(value, str):\n",
    "        return True\n",
    "    else:\n",
    "        return not math.isnan(value)\n",
    "\n",
    "def visualize_group_grades(group_dfs, run_number, run_length, rep_number, window):\n",
    "    assert run_number < len(group_dfs['1']), \"Not enough runs\"\n",
    "    assert isinstance(group_dfs['1'][run_number][rep_number]['step_grade'][1], str), \"Not a graded run\"\n",
    "    grade_list = [\"F-\", \"F\", \"F+\",\n",
    "    \t\t\t\t\"D-\", \"D\", \"D+\",\n",
    "    \t\t\t\t\"C-\", \"C\", \"C+\",\n",
    "\t\t\t\t\t\"B-\", \"B\", \"B+\",\n",
    "\t\t\t\t\t\"A-\", \"A\", \"A+\"]\n",
    "    grade_dict = {grade: i for i, grade in enumerate(grade_list)}\n",
    "    \n",
    "    group_dict = {}\n",
    "    for group, runs in group_dfs.items():\n",
    "        group_dict[group] = runs[run_number][rep_number]\n",
    "    \n",
    "    # Create a figure and axis\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    # Initialize lines for each group\n",
    "    lines = {}\n",
    "    for group in group_dict.keys():\n",
    "        lines[group], = ax.plot([], [], label=group)\n",
    "    ax.set_ylim(1, 15)\n",
    "    y_ticks = list(range(1, 16))\n",
    "    ax.set_yticks(y_ticks)\n",
    "    ax.set_yticklabels(grade_list, fontsize = 6)\n",
    "    ax.legend(loc='upper left')\n",
    "\n",
    "    # tracking text for proper clearance\n",
    "    labels = []\n",
    "\n",
    "    for i in range(run_length - window):\n",
    "        for x in labels:\n",
    "            try:\n",
    "                x.remove()\n",
    "            except:\n",
    "                pass\n",
    "        ax.set_title(f\"Timestep: {i + 1}\")\n",
    "        for group, data in group_dict.items():\n",
    "            x_data = list(range(i, i+window))\n",
    "            y_data = [grade_dict[grade] if isnan(grade) else -1 for grade in data['step_grade'][i:i+window]]\n",
    "            lines[group].set_data(x_data, y_data)\n",
    "\n",
    "            # adding social loafing markers\n",
    "            for j, possible_detection in enumerate(data['loafing_detected'][i:i+window]):\n",
    "                if possible_detection:\n",
    "                    ax.plot(x_data[j], y_data[j],'o', color='red', markersize=3)\n",
    "                    label = ax.text(x_data[j], y_data[j], \"loaf\", fontsize=8)\n",
    "                    labels.append(label)\n",
    "        plt.pause(0.1)\n",
    "        display(fig)\n",
    "        clear_output(wait=True)\n",
    "        ax.set_xlim(i+1, i + window*2)\n",
    "    plt.ioff()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a51deeb-9aba-4307-b756-0d9f1ffccaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gui_visualize(agent_dfs, group_dfs, run_number, rep_number, run_length):\n",
    "    group_dict = {}\n",
    "    agent_dict = {}\n",
    "    group_locations = {}\n",
    "    taken_group_locations = []\n",
    "    agent_locations = {}\n",
    "    for group, runs in group_dfs.items():\n",
    "        group_dict[group] = runs[run_number][rep_number]\n",
    "    for agent, runs in agent_dfs.items():\n",
    "        agent_dict[agent] = runs[run_number][rep_number]\n",
    "    # agents and groups gotten for the run\n",
    "    # now, create a matplotlib to plot them on\n",
    "    for i in range(run_length):\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.set_title(f\"Timestep: {i + 1}\")\n",
    "        ax.set_xlim(0, 100)\n",
    "        ax.set_ylim(0, 100)\n",
    "        ax.axis('off')\n",
    "        ax.set_aspect('equal')\n",
    "        for group, group_data in group_dict.items():\n",
    "            if group not in group_locations:\n",
    "                temp = (random.randint(0, 100), random.randint(0, 100))\n",
    "                while temp in taken_group_locations:\n",
    "                    temp = (random.randint(0, 100), random.randint(0, 100))\n",
    "                group_locations[group] = temp\n",
    "            ax.plot(group_locations[group][0], group_locations[group][1], 'o', color='red', markersize=3)\n",
    "            ax.text(group_locations[group][0] + 1, group_locations[group][1] + 1, group_data['step_grade'][i], fontsize=8, verticalalignment='bottom', horizontalalignment='left')\n",
    "        plt.draw()\n",
    "        plt.pause(0.1)\n",
    "        clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f0c7c88-2386-4280-bd33-5d0f79de84a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m gui_visualize(agent_dfs, group_dfs, run_number \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, rep_number\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m, run_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m200\u001b[39m)\n",
      "Cell \u001b[1;32mIn[10], line 29\u001b[0m, in \u001b[0;36mgui_visualize\u001b[1;34m(agent_dfs, group_dfs, run_number, rep_number, run_length)\u001b[0m\n\u001b[0;32m     27\u001b[0m     ax\u001b[38;5;241m.\u001b[39mtext(group_locations[group][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, group_locations[group][\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, group_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep_grade\u001b[39m\u001b[38;5;124m'\u001b[39m][i], fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, verticalalignment\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbottom\u001b[39m\u001b[38;5;124m'\u001b[39m, horizontalalignment\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     28\u001b[0m plt\u001b[38;5;241m.\u001b[39mdraw()\n\u001b[1;32m---> 29\u001b[0m plt\u001b[38;5;241m.\u001b[39mpause(\u001b[38;5;241m0.1\u001b[39m)\n\u001b[0;32m     30\u001b[0m clear_output(wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_cooperation\\Lib\\site-packages\\matplotlib\\pyplot.py:756\u001b[0m, in \u001b[0;36mpause\u001b[1;34m(interval)\u001b[0m\n\u001b[0;32m    754\u001b[0m         canvas\u001b[38;5;241m.\u001b[39mdraw_idle()\n\u001b[0;32m    755\u001b[0m     show(block\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 756\u001b[0m     canvas\u001b[38;5;241m.\u001b[39mstart_event_loop(interval)\n\u001b[0;32m    757\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    758\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(interval)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\my_cooperation\\Lib\\site-packages\\matplotlib\\backend_bases.py:2392\u001b[0m, in \u001b[0;36mFigureCanvasBase.start_event_loop\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   2390\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_looping \u001b[38;5;129;01mand\u001b[39;00m counter \u001b[38;5;241m*\u001b[39m timestep \u001b[38;5;241m<\u001b[39m timeout:\n\u001b[0;32m   2391\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflush_events()\n\u001b[1;32m-> 2392\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(timestep)\n\u001b[0;32m   2393\u001b[0m     counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gui_visualize(agent_dfs, group_dfs, run_number = 1, rep_number= '1', run_length = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "549233ba-bebd-434c-9b0a-f0957746cfe5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m visualize_group_grades(group_dfs, run_number\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, rep_number \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m, run_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m, window\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m)\n",
      "Cell \u001b[1;32mIn[9], line 9\u001b[0m, in \u001b[0;36mvisualize_group_grades\u001b[1;34m(group_dfs, run_number, run_length, rep_number, window)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvisualize_group_grades\u001b[39m(group_dfs, run_number, run_length, rep_number, window):\n\u001b[1;32m----> 9\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m run_number \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(group_dfs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m]), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot enough runs\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(group_dfs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m][run_number][rep_number][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep_grade\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mstr\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot a graded run\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     11\u001b[0m     grade_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF-\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF+\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     12\u001b[0m     \t\t\t\t\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD-\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD+\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     13\u001b[0m     \t\t\t\t\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC-\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC+\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     14\u001b[0m \t\t\t\t\t\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB-\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB+\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     15\u001b[0m \t\t\t\t\t\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA-\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA+\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;31mKeyError\u001b[0m: '1'"
     ]
    }
   ],
   "source": [
    "visualize_group_grades(group_dfs, run_number=0, rep_number = '1', run_length=200, window=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439d6da2-1456-4520-85ab-e50fae521434",
   "metadata": {},
   "outputs": [],
   "source": [
    "for agent, agent_run in group_dfs.items():\n",
    "    print(agent)\n",
    "    print(agent_run[1].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1c818c-89f8-40be-8cc9-4020be3b3645",
   "metadata": {},
   "outputs": [],
   "source": [
    "for agent, agent_run in agent_dfs.items():\n",
    "    print(agent)\n",
    "    print(agent_run[1].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500e67b5-fe85-4239-8561-ba1eaead5876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify social loafing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0126b39c-0970-4fea-8085-61cb173fcb93",
   "metadata": {},
   "source": [
    "# Visualization techniques to look into\n",
    "Heatmaps\n",
    "Want to plot the trjectory of the run, with variance accross runs.\n",
    "\n",
    "Stable groups?\n",
    "How do we decide when a group has \"filtered out\" social loafing behavior?\n",
    "First, let's track the loafing detection for each group, does it every stabilize?\n",
    "We can use a line plot to track this. Use the code for tracking grades, and adapt to track number of groups that detected loafing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce04617d-2bc0-4168-b975-1e10f09d29fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<string>, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m<string>:15\u001b[1;36m\u001b[0m\n\u001b[1;33m    tracking_loafing_detected.append(loafing_detected)\u001b[0m\n\u001b[1;37m                                                      ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "def track_loafing(group_dfs, run_number, rep_number, run_length, window = 8):\n",
    "    interested_groups = {}\n",
    "    for group, data in group_dfs.items():\n",
    "        interested_groups[group] = data[run_number][rep_number]\n",
    "    num_groups = len(interested_groups)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    tracking_loafing_detected = []\n",
    "\n",
    "    for i in range(run_length):\n",
    "         for group, data in interested_groups.items():\n",
    "            if (data['loafing_detected'][i]):\n",
    "                loafing_detected += 1\n",
    "        tracking_loafing_detected.append(loafing_detected)\n",
    "    \n",
    "    for i in range(run_length - window):\n",
    "        loafing_detected = 0\n",
    "        ax.set_title(f\"Number of Groups That Detected Loafing. Timestep: {i + 1}\")\n",
    "        ax.set_ylim(0, num_groups)\n",
    "        x_data = list(range(i, i+window))\n",
    "        y_data = tracking_loafing_detected[i:i+window]\n",
    "        ax.plot(x_data, y_data)\n",
    "        \n",
    "        plt.pause(0.1)\n",
    "        display(fig)\n",
    "        clear_output(wait=True)\n",
    "        ax.set_xlim(i+1, i + window*2)\n",
    "    return tracking_loafing_detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375db2bc-b084-4e82-8bfa-be17757a1be6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
