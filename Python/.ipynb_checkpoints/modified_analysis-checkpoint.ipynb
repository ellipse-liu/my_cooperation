{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9291bb2e-c9b4-4f71-9c6d-bf6d5e6578aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 imports\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import io\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "import matplotlib.animation\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26ff2a0e-315e-4b60-8515-f739c09e7255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 runfile directories\n",
    "runfile_directory = 'Runfiles/'\n",
    "results_directory = 'Results/'\n",
    "template_file = 'template.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1eb5a622-a41f-4e5f-b951-9e2dbb9e9696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 parameter dict and template writing functions\n",
    "parameter_dict = {'*fname': ['Python/Results/'],\n",
    "                  'steps': ['200'],\n",
    "                 'reps': ['50'],\n",
    "                 'letter_grades' : ['true'],\n",
    "                  'prefix' : [\"adjusted_sweeps\"],\n",
    "                  'grading_error_alpha' : ['150.0'],\n",
    "                  'grading_error_beta' : ['150.0'],\n",
    "                  'divorce_constant' : ['100',  '50', '25', '10', '0'],\n",
    "                  'max_strikes' : ['3', '5', '7', '11', '13'],\n",
    "                  'num_agents' : ['60'],\n",
    "                  'agent_tolerance_alpha' : ['1.0' , '3.0'], # (1,1), else alpha < beta for tolerance, with a hard cap of 4 grades down, old: '1.', '2.', '3.0', '4.0', '5.0'\n",
    "                  'agent_tolerance_beta' : ['1.0', '5.0'], #old '1.', '3.', '5.', '7.0', '8.0', '10.0'\n",
    "                  'agent_effort_alpha' : ['5.', '7.5', '10.', '12.5', '15.'],\n",
    "                  'agent_effort_beta' : ['3.', '5.', '7.', '9.', '10.'], # effort beta < effort alpha\n",
    "                  'agent_std_effort' : ['0.01', '0.05', '0.075', '0.1', '0.2'],\n",
    "                  'min_agents_per_group' : ['3'],\n",
    "                  'max_agents_per_group' : ['4'],\n",
    "                 }\n",
    "\n",
    "def design_runfile(new_fname, parameter_dict=parameter_dict):\n",
    "    with open(template_file) as template:\n",
    "        template_lines = template.readlines()\n",
    "\n",
    "    parameter_dict['*fname'] = [parameter_dict['*fname'][0] + new_fname.strip('.txt')]\n",
    "    \n",
    "    with open(runfile_directory + new_fname, 'w+') as new_file:\n",
    "        for line in template_lines:\n",
    "            param = line.split()[0]\n",
    "            if param not in parameter_dict:\n",
    "                new_file.write(line)\n",
    "            else:\n",
    "                fixer_upper = line.strip('\\n').split()[:2]\n",
    "                new_line = ' '.join(fixer_upper + (parameter_dict[param])) + '\\n'\n",
    "                new_file.write(new_line)\n",
    "                \n",
    "def delete_old_files(agent_dir, group_dir):\n",
    "    agent_files = os.listdir(agent_dir)\n",
    "    group_files = os.listdir(group_dir)\n",
    "    for file_name in agent_files:\n",
    "        file_path = os.path.join(agent_dir, file_name)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)  # Remove the file or link\n",
    "        except Exception as e:\n",
    "            print(f'Failed to delete {file_path}. Reason: {e}')\n",
    "    for file_name in group_files:\n",
    "        file_path = os.path.join(group_dir, file_name)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)  # Remove the file or link\n",
    "        except Exception as e:\n",
    "            print(f'Failed to delete {file_path}. Reason: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88ab3136-1780-458c-88b0-2c03351e0296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 Create the run file\n",
    "design_runfile('adjusted_sweeps.txt', parameter_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0e8c9a3-4153-4c2e-9a00-9f8d6db3cd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL NUKE OLD FILES\n",
    "delete_old_files(\"Agent_data/\", \"Group_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d2e69f5-0018-4831-9c07-8f3ed97d1043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 Agent and group analysis directories\n",
    "result_prefix = \"adjusted_sweeps\"\n",
    "agent_directory = \"Agent_data/\"\n",
    "agent_file_prefix = result_prefix + \"adjusted_sweeps_Agent-\"\n",
    "group_directory = \"Group_data/\"\n",
    "group_file_prefix = result_prefix + \"adjusted_sweeps_Group-\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "70abda62-8048-4502-8419-d71db156ed3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 agent and group intake functions\n",
    "existing_runs = {}\n",
    "existing_run_tracker = 0\n",
    "\n",
    "def get_agent_results(agent_file_prefix, time_steps):\n",
    "    agent_dfs = {}\n",
    "    global existing_runs, existing_run_tracker # get the existing runs\n",
    "    for filename in os.listdir(agent_directory): # for each file in the os\n",
    "        file_path = os.path.join(agent_directory, filename)\n",
    "        # Check if it's a regular file (not a directory)\n",
    "        if os.path.isfile(file_path):\n",
    "            temp = open(file_path, 'r')\n",
    "            read = temp.readlines()\n",
    "            temp_lines = [line for line in read if not line.startswith('#')] # get lines for reading pure dfs\n",
    "            i2h, h2i, seeds = get_headers(read) # get i2h, h2i, seeds in order\n",
    "            num_sections = len(temp_lines)//(time_steps+1)\n",
    "            df_set = {}\n",
    "            for i in range(num_sections): # for each RUN\n",
    "                filtered_csv_string = ''.join(temp_lines)\n",
    "                csv_io = io.StringIO(filtered_csv_string)\n",
    "                df = pd.read_csv(csv_io, skiprows = i*(time_steps+1), nrows = time_steps, comment=\"#\")\n",
    "                if i2h[i] not in existing_runs: # if header is not marked as a run\n",
    "                    existing_runs[i2h[i]] = existing_run_tracker\n",
    "                    existing_run_tracker += 1 # create an existing run\n",
    "                    if i not in df_set: # if run number is not in the dfset assigned to current agent\n",
    "                        df_set[i] = {seeds[i]:df} # df_set -> run -> rep #create a new dict with seed #\n",
    "                    else:\n",
    "                        df_set[i][seeds[i]] = df # otherwise add a rep to the thing in df\n",
    "                else:\n",
    "                    if existing_runs[i2h[i]] not in df_set:\n",
    "                        df_set[existing_runs[i2h[i]]] = {seeds[i]:df}\n",
    "                    else:\n",
    "                        df_set[existing_runs[i2h[i]]][seeds[i]] = df\n",
    "            agent_dfs[filename.strip(agent_file_prefix).strip(\".txt\")] = df_set\n",
    "    return agent_dfs\n",
    "\n",
    "def get_group_results(group_file_prefix, time_steps):\n",
    "    group_dfs = {}\n",
    "\n",
    "    global existing_runs, existing_run_tracker\n",
    "    \n",
    "    for filename in os.listdir(group_directory):\n",
    "        file_path = os.path.join(group_directory, filename)\n",
    "        # Check if it's a regular file (not a directory)\n",
    "        if os.path.isfile(file_path):\n",
    "            temp = open(file_path, 'r')\n",
    "            read = temp.readlines()\n",
    "            temp_lines = [line for line in read if not line.startswith('#')]\n",
    "            i2h, h2i, seeds = get_headers(read)\n",
    "            num_sections = len(temp_lines)//(time_steps+1)\n",
    "            df_set = {}\n",
    "            for i in range(num_sections):\n",
    "                filtered_csv_string = ''.join(temp_lines)\n",
    "                csv_io = io.StringIO(filtered_csv_string)\n",
    "                df = pd.read_csv(csv_io, skiprows = i*(time_steps+1), nrows = time_steps, comment=\"#\")\n",
    "                if i2h[i] not in existing_runs:\n",
    "                    existing_runs[i2h[i]] = existing_run_tracker\n",
    "                    existing_run_tracker += 1\n",
    "                    if i not in df_set:\n",
    "                        df_set[i] = {seeds[i]:df}\n",
    "                    else:\n",
    "                        df_set[i][seeds[i]] = df\n",
    "                else:\n",
    "                    if existing_runs[i2h[i]] not in df_set:\n",
    "                        df_set[existing_runs[i2h[i]]] = {seeds[i]:df}\n",
    "                    else:\n",
    "                        df_set[existing_runs[i2h[i]]][seeds[i]] = df\n",
    "            group_dfs[filename.strip(group_file_prefix).strip(\".txt\")] = df_set\n",
    "    return group_dfs\n",
    "\n",
    "def get_headers(lines): #gets headers and sorts them in order to align runs i use seeds, a fixed order array in order to track which seed run[i] is on\n",
    "    header_dicts = {}\n",
    "    seeds = []\n",
    "    reading_headers = False\n",
    "    current_counter = 0\n",
    "    headed = \"\"\n",
    "    for line in lines:\n",
    "        if not reading_headers:\n",
    "            if line.startswith('#') and 'curr_seed' not in line:\n",
    "                reading_headers = True\n",
    "                headed += line.strip('\\n')\n",
    "        else:\n",
    "            if not line.startswith('#'):\n",
    "                reading_headers = False\n",
    "                header_dicts[current_counter] = headed\n",
    "                current_counter += 1\n",
    "                headed = \"\"\n",
    "            else:\n",
    "                if 'currseed' in line:\n",
    "                    seeds.append(line.strip('\\n').split(': ')[1])\n",
    "                else:\n",
    "                    headed += line.strip('\\n')\n",
    "    return header_dicts, {x:y for y,x in header_dicts.items()}, seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "69e56d2d-0d57-4278-865f-d46315cd827d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 get agent and group dfs\n",
    "agent_dfs = get_agent_results(agent_file_prefix, 200)\n",
    "group_dfs = get_group_results(group_file_prefix, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf85e9b-42c5-4fb3-a5d2-2c5e20fd66e2",
   "metadata": {},
   "source": [
    "# Updated Visualizations\n",
    "## Brainstorming\n",
    "What kind of visualization would be good?\n",
    "\n",
    "For starters, let's try re-creating the GUI of the experiment in a function and matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "fe10f21b-e0fb-4bcb-b7fd-f2b32afcb477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for visualizing the grades of each group growing up and down\n",
    "def isnan(value):\n",
    "    if isinstance(value, str):\n",
    "        return True\n",
    "    else:\n",
    "        return not math.isnan(value)\n",
    "\n",
    "def visualize_group_grades(group_dfs, run_number, run_length, rep_number, window):\n",
    "    assert run_number < len(group_dfs['1']), \"Not enough runs\"\n",
    "    assert isinstance(group_dfs['1'][run_number][rep_number]['step_grade'][1], str), \"Not a graded run\"\n",
    "    grade_list = [\"F-\", \"F\", \"F+\",\n",
    "    \t\t\t\t\"D-\", \"D\", \"D+\",\n",
    "    \t\t\t\t\"C-\", \"C\", \"C+\",\n",
    "\t\t\t\t\t\"B-\", \"B\", \"B+\",\n",
    "\t\t\t\t\t\"A-\", \"A\", \"A+\"]\n",
    "    grade_dict = {grade: i for i, grade in enumerate(grade_list)}\n",
    "    \n",
    "    group_dict = {}\n",
    "    for group, runs in group_dfs.items():\n",
    "        group_dict[group] = runs[run_number][rep_number]\n",
    "    \n",
    "    # Create a figure and axis\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    # Initialize lines for each group\n",
    "    lines = {}\n",
    "    for group in group_dict.keys():\n",
    "        lines[group], = ax.plot([], [], label=group)\n",
    "    ax.set_ylim(1, 15)\n",
    "    y_ticks = list(range(1, 16))\n",
    "    ax.set_yticks(y_ticks)\n",
    "    ax.set_yticklabels(grade_list, fontsize = 6)\n",
    "    ax.legend(loc='upper left')\n",
    "\n",
    "    # tracking text for proper clearance\n",
    "    labels = []\n",
    "\n",
    "    for i in range(run_length - window):\n",
    "        for x in labels:\n",
    "            try:\n",
    "                x.remove()\n",
    "            except:\n",
    "                pass\n",
    "        ax.set_title(f\"Timestep: {i + 1}\")\n",
    "        for group, data in group_dict.items():\n",
    "            x_data = list(range(i, i+window))\n",
    "            y_data = [grade_dict[grade] if isnan(grade) else -1 for grade in data['step_grade'][i:i+8]]\n",
    "            lines[group].set_data(x_data, y_data)\n",
    "\n",
    "            # adding social loafing markers\n",
    "            for j, possible_detection in enumerate(data['loafing_detected'][i:i+8]):\n",
    "                if possible_detection:\n",
    "                    ax.plot(x_data[j], y_data[j],'o', color='red', markersize=3)\n",
    "                    label = ax.text(x_data[j], y_data[j], \"loaf\", fontsize=8)\n",
    "                    labels.append(label)\n",
    "        plt.pause(0.1)\n",
    "        display(fig)\n",
    "        clear_output(wait=True)\n",
    "        ax.set_xlim(i+1, i + window*2)\n",
    "    plt.ioff()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "0a51deeb-9aba-4307-b756-0d9f1ffccaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gui_visualize(agent_dfs, group_dfs, run_number, rep_number, run_length):\n",
    "    group_dict = {}\n",
    "    agent_dict = {}\n",
    "    group_locations = {}\n",
    "    taken_group_locations = []\n",
    "    agent_locations = {}\n",
    "    for group, runs in group_dfs.items():\n",
    "        group_dict[group] = runs[run_number][rep_number]\n",
    "    for agent, runs in agent_dfs.items():\n",
    "        agent_dict[agent] = runs[run_number][rep_number]\n",
    "    # agents and groups gotten for the run\n",
    "    # now, create a matplotlib to plot them on\n",
    "    for i in range(run_length):\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.set_title(f\"Timestep: {i + 1}\")\n",
    "        ax.set_xlim(0, 100)\n",
    "        ax.set_ylim(0, 100)\n",
    "        ax.axis('off')\n",
    "        ax.set_aspect('equal')\n",
    "        for group, group_data in group_dict.items():\n",
    "            if group not in group_locations:\n",
    "                temp = (random.randint(0, 100), random.randint(0, 100))\n",
    "                while temp in taken_group_locations:\n",
    "                    temp = (random.randint(0, 100), random.randint(0, 100))\n",
    "                group_locations[group] = temp\n",
    "            ax.plot(group_locations[group][0], group_locations[group][1], 'o', color='red', markersize=3)\n",
    "            ax.text(group_locations[group][0] + 1, group_locations[group][1] + 1, group_data['step_grade'][i], fontsize=8, verticalalignment='bottom', horizontalalignment='left')\n",
    "        plt.draw()\n",
    "        plt.pause(0.1)\n",
    "        clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "6f0c7c88-2386-4280-bd33-5d0f79de84a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[193], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m gui_visualize(agent_dfs, group_dfs, run_number \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, rep_number\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m, run_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m200\u001b[39m)\n",
      "Cell \u001b[1;32mIn[178], line 10\u001b[0m, in \u001b[0;36mgui_visualize\u001b[1;34m(agent_dfs, group_dfs, run_number, rep_number, run_length)\u001b[0m\n\u001b[0;32m      8\u001b[0m     group_dict[group] \u001b[38;5;241m=\u001b[39m runs[run_number][rep_number]\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m agent, runs \u001b[38;5;129;01min\u001b[39;00m agent_dfs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m---> 10\u001b[0m     agent_dict[agent] \u001b[38;5;241m=\u001b[39m runs[run_number][rep_number]\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# agents and groups gotten for the run\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# now, create a matplotlib to plot them on\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(run_length):\n",
      "\u001b[1;31mKeyError\u001b[0m: '1'"
     ]
    }
   ],
   "source": [
    "gui_visualize(agent_dfs, group_dfs, run_number = 1, rep_number= '1', run_length = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "58a52431-140c-477d-80e6-33dbbcd8c879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values([0, 1, 2, 3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "print(existing_runs.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "549233ba-bebd-434c-9b0a-f0957746cfe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "visualize_group_grades(group_dfs, run_number=0, rep_number = '1', run_length=200, window=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "439d6da2-1456-4520-85ab-e50fae521434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "dict_keys(['1', '2'])\n",
      "10\n",
      "dict_keys(['1', '2'])\n",
      "11\n",
      "dict_keys(['1', '2'])\n",
      "12\n",
      "dict_keys(['1', '2'])\n",
      "13\n",
      "dict_keys(['1', '2'])\n",
      "14\n",
      "dict_keys(['1', '2'])\n",
      "15\n",
      "dict_keys(['1', '2'])\n",
      "16\n",
      "dict_keys(['1', '2'])\n",
      "17\n",
      "dict_keys(['1', '2'])\n",
      "18\n",
      "dict_keys(['1', '2'])\n",
      "19\n",
      "dict_keys(['1', '2'])\n",
      "2\n",
      "dict_keys(['1', '2'])\n",
      "20\n",
      "dict_keys(['1', '2'])\n",
      "3\n",
      "dict_keys(['1', '2'])\n",
      "4\n",
      "dict_keys(['1', '2'])\n",
      "5\n",
      "dict_keys(['1', '2'])\n",
      "6\n",
      "dict_keys(['1', '2'])\n",
      "7\n",
      "dict_keys(['1', '2'])\n",
      "8\n",
      "dict_keys(['1', '2'])\n",
      "9\n",
      "dict_keys(['1', '2'])\n"
     ]
    }
   ],
   "source": [
    "for agent, agent_run in group_dfs.items():\n",
    "    print(agent)\n",
    "    print(agent_run[1].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "8b1c818c-89f8-40be-8cc9-4020be3b3645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "dict_keys(['2'])\n",
      "10\n",
      "dict_keys(['1', '2'])\n",
      "11\n",
      "dict_keys(['1', '2'])\n",
      "12\n",
      "dict_keys(['1', '2'])\n",
      "13\n",
      "dict_keys(['1', '2'])\n",
      "14\n",
      "dict_keys(['1', '2'])\n",
      "15\n",
      "dict_keys(['1', '2'])\n",
      "16\n",
      "dict_keys(['1', '2'])\n",
      "17\n",
      "dict_keys(['1', '2'])\n",
      "18\n",
      "dict_keys(['1', '2'])\n",
      "19\n",
      "dict_keys(['1', '2'])\n",
      "2\n",
      "dict_keys(['1', '2'])\n",
      "20\n",
      "dict_keys(['1', '2'])\n",
      "21\n",
      "dict_keys(['1', '2'])\n",
      "22\n",
      "dict_keys(['1', '2'])\n",
      "23\n",
      "dict_keys(['1', '2'])\n",
      "24\n",
      "dict_keys(['1', '2'])\n",
      "25\n",
      "dict_keys(['1', '2'])\n",
      "26\n",
      "dict_keys(['1', '2'])\n",
      "27\n",
      "dict_keys(['1', '2'])\n",
      "28\n",
      "dict_keys(['1', '2'])\n",
      "29\n",
      "dict_keys(['1', '2'])\n",
      "3\n",
      "dict_keys(['1', '2'])\n",
      "30\n",
      "dict_keys(['1', '2'])\n",
      "31\n",
      "dict_keys(['1', '2'])\n",
      "32\n",
      "dict_keys(['1', '2'])\n",
      "33\n",
      "dict_keys(['1', '2'])\n",
      "34\n",
      "dict_keys(['1', '2'])\n",
      "35\n",
      "dict_keys(['1', '2'])\n",
      "36\n",
      "dict_keys(['1', '2'])\n",
      "37\n",
      "dict_keys(['1', '2'])\n",
      "38\n",
      "dict_keys(['1', '2'])\n",
      "39\n",
      "dict_keys(['1', '2'])\n",
      "4\n",
      "dict_keys(['1', '2'])\n",
      "40\n",
      "dict_keys(['1', '2'])\n",
      "41\n",
      "dict_keys(['1', '2'])\n",
      "42\n",
      "dict_keys(['1', '2'])\n",
      "43\n",
      "dict_keys(['1', '2'])\n",
      "44\n",
      "dict_keys(['1', '2'])\n",
      "45\n",
      "dict_keys(['1', '2'])\n",
      "46\n",
      "dict_keys(['1', '2'])\n",
      "47\n",
      "dict_keys(['1', '2'])\n",
      "48\n",
      "dict_keys(['1', '2'])\n",
      "49\n",
      "dict_keys(['1', '2'])\n",
      "5\n",
      "dict_keys(['1', '2'])\n",
      "50\n",
      "dict_keys(['1', '2'])\n",
      "51\n",
      "dict_keys(['1', '2'])\n",
      "52\n",
      "dict_keys(['1', '2'])\n",
      "53\n",
      "dict_keys(['1', '2'])\n",
      "54\n",
      "dict_keys(['1', '2'])\n",
      "55\n",
      "dict_keys(['1', '2'])\n",
      "56\n",
      "dict_keys(['1', '2'])\n",
      "57\n",
      "dict_keys(['1', '2'])\n",
      "58\n",
      "dict_keys(['1', '2'])\n",
      "59\n",
      "dict_keys(['1', '2'])\n",
      "6\n",
      "dict_keys(['1', '2'])\n",
      "60\n",
      "dict_keys(['1', '2'])\n",
      "7\n",
      "dict_keys(['1', '2'])\n",
      "8\n",
      "dict_keys(['1', '2'])\n",
      "9\n",
      "dict_keys(['1', '2'])\n"
     ]
    }
   ],
   "source": [
    "for agent, agent_run in agent_dfs.items():\n",
    "    print(agent)\n",
    "    print(agent_run[1].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500e67b5-fe85-4239-8561-ba1eaead5876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify social loafing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0126b39c-0970-4fea-8085-61cb173fcb93",
   "metadata": {},
   "source": [
    "# Visualization techniques to look into\n",
    "Heatmaps\n",
    "Want to plot the trjectory of the run, with variance accross runs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
