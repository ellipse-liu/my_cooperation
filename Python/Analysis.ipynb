{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44624c7d-e1d4-4c86-991d-4b1099f50d5e",
   "metadata": {},
   "source": [
    "# Data Analysis and Sweep Parameter File Automation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5fdf35-dc2f-4560-93d6-ce298c371bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636002b7-cb50-491c-a47d-030a75de042f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting directories and globals\n",
    "runfile_directory = 'Runfiles/'\n",
    "results_directory = 'Results/'\n",
    "template_file = 'template.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bf18da-5e86-4417-a473-ac86f71f5a23",
   "metadata": {},
   "source": [
    "# TWEAKS MADE 4/28/24\n",
    "HEY I MADE SOME TWEAKS TO THE ORIGINAL PARAMETER VALUES\n",
    "Mean_tolerance dropped from 1.0 -> 0.5, 1.0 setting is too high for variation. 0.5 is more indicative of realistic thresholds for expectation of effort, std deviations also dropped to be half of  the mean\n",
    "\n",
    "# Thinking through an issue 5/28\n",
    "Why don't agents ever rejoin a group? Simply put, and agent will never rejoin because the bounds for their tolerance is essentially overlapped with their bounds for effort\n",
    "\n",
    "How can I adjust the model to include to benefit of working in a team? The data show that students retain information better in a group; I think that we should increase the variation/stdev for the individual agent effort output normal curve\n",
    "\n",
    "Should also tweak the standard mean_tolerance to be lower, so that it matches agent_std_value, with the intuition that the average person is going to be forgiving within 1 std dev of someone's normal output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f93549-dd76-43bc-9985-afa0e83586dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables of interest, and file name specifications\n",
    "\n",
    "# new parameter dict with new model\n",
    "parameter_dict = {'*fname': ['Python/Results/'],\n",
    "                  'steps': ['100'],\n",
    "                 'reps': ['1'],\n",
    "                 'letter_grades' : ['true', 'false'],\n",
    "                  'prefix' : [\"new_model_test\"],\n",
    "                  'grading_error_alpha' : ['2.5'],\n",
    "                  'grading_error_beta' : ['2.5'],\n",
    "                  'divorce_constant' : ['1000'],\n",
    "                  'max_strikes' : ['3'],\n",
    "                  'num_agents' : ['60'],\n",
    "                  'agent_tolerance_alpha' : ['0.1'],\n",
    "                  'agent_tolerance_beta' : ['0.1'],\n",
    "                  'agent_effort_alpha' : ['0.1'],\n",
    "                  'agent_effort_beta' : ['0.1'],\n",
    "                  'agent_std_effort' : ['0.5'],\n",
    "                  'min_agents_per_group' : ['3'],\n",
    "                  'max_agents_per_group' : ['4'],\n",
    "                  \n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff5d372-1269-4d25-a5c8-052f6dd34319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to modify the sweep file based on the parameters in parameteer_dict\n",
    "\n",
    "def design_runfile(new_fname, parameter_dict=parameter_dict):\n",
    "    with open(template_file) as template:\n",
    "        template_lines = template.readlines()\n",
    "\n",
    "    parameter_dict['*fname'] = [parameter_dict['*fname'][0] + new_fname.strip('.txt')]\n",
    "    \n",
    "    with open(runfile_directory + new_fname, 'w+') as new_file:\n",
    "        for line in template_lines:\n",
    "            param = line.split()[0]\n",
    "            if param not in parameter_dict:\n",
    "                new_file.write(line)\n",
    "            else:\n",
    "                fixer_upper = line.strip('\\n').split()[:2]\n",
    "                new_line = ' '.join(fixer_upper + (parameter_dict[param])) + '\\n'\n",
    "                new_file.write(new_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abe12a8-7583-432e-ba31-1dc805dd5dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "design_runfile('new_model_test.txt', parameter_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a1cb2b-e301-40b0-89df-473a6f98c1e8",
   "metadata": {},
   "source": [
    "# Actually Analyzing the Files after Sweeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c281e5-b086-4222-aeac-48cd2228896a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for pulling from results. returns spefic dfs for each level of granularity\n",
    "def get_results(result_prefix):\n",
    "    time_df = pd.read_csv(results_directory + result_prefix + 'timeresults.txt', skiprows=6)\n",
    "    end_df = pd.read_csv(results_directory + result_prefix + 'endresults.txt', skiprows=6)\n",
    "    return time_df, end_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a39733-1c46-4af3-bb92-45f541f686c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "result_prefix = \"new_model_test\"\n",
    "\n",
    "time_df, end_df = get_results(result_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4289eeec-8ba7-493f-8716-97f4bd2750a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "interested_independent_variable = 'deviant_mean_tolerance'\n",
    "interested_dependent_variable = 'avg_deviant_payoff'\n",
    "interested_dependent_variable_two = 'avg_standard_payoff'\n",
    "\n",
    "def sort_by_sweep(time_df, interested_independent_variable, interested_dependent_variable, steps):\n",
    "    dfs = [time_df[i:i+steps] for i in range(0, len(time_df), steps)]\n",
    "    \n",
    "    plt.figure()\n",
    "    \n",
    "    for df in dfs:\n",
    "        x = df[\"Timestep\"]\n",
    "        y = df[interested_dependent_variable]\n",
    "        y_two = df[interested_dependent_variable_two]\n",
    "        \n",
    "        interested_var_value = df[interested_independent_variable].iloc[0]\n",
    "        \n",
    "        plt.plot(x, y, linestyle='-', label=interested_dependent_variable)\n",
    "        plt.plot(x, y_two, linestyle='-', label=interested_dependent_variable_two)\n",
    "\n",
    "        # Add title and labels\n",
    "        plt.title(f\"{interested_independent_variable}={interested_var_value}\")\n",
    "        plt.xlabel(\"Timesteps\")\n",
    "        plt.ylabel(\"Average payoffs\")\n",
    "        \n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "def sort_by_sweep_but_relational(time_df, interested_independent_variable, interested_dependent_variable, steps):\n",
    "    dfs = [time_df[i:i+steps] for i in range(0, len(time_df), steps)]\n",
    "    \n",
    "    plt.figure()\n",
    "    \n",
    "    for df in dfs:\n",
    "        x = df[\"Timestep\"].copy()[1:]\n",
    "        y = df[interested_dependent_variable].copy()[1:]\n",
    "        shift = [0] + list(y[:-1])\n",
    "        \n",
    "        y = [y_curr - y_prev for y_curr, y_prev in zip(y,shift)]\n",
    "        \n",
    "        \n",
    "        y_two = df[interested_dependent_variable_two].copy()[1:]\n",
    "        shift_two = [0] +  list(y_two[:-1])\n",
    "        \n",
    "        y_two = [y_curr - y_prev for y_curr, y_prev in zip(y_two,shift_two)]\n",
    "        \n",
    "        interested_var_value = df[interested_independent_variable].copy().iloc[0]\n",
    "        \n",
    "        plt.plot(x, y, linestyle='-', label=interested_dependent_variable)\n",
    "        plt.plot(x, y_two, linestyle='-', label=interested_dependent_variable_two)\n",
    "\n",
    "        # Add title and labels\n",
    "        plt.title(f\"Relative payoffs when {interested_independent_variable}={interested_var_value}\")\n",
    "        plt.xlabel(\"Timesteps\")\n",
    "        plt.ylabel(\"Average relative payoff\")\n",
    "        \n",
    "        plt.ylim(0.10, 0.4)\n",
    "        \n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d83a4e-659b-4643-a832-5342f2df29cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sort_by_sweep(time_df,interested_independent_variable, interested_dependent_variable, 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519b6185-8306-4fb0-a08e-d94ba87e7fad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sort_by_sweep_but_relational(time_df,interested_independent_variable, interested_dependent_variable, 101)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bca546b-63fe-49a3-89b1-af6a3230626f",
   "metadata": {},
   "source": [
    "# Analyzing Agent Files\n",
    "I've  hacked together some semblance of agent data collection with raw file writing, oh and 4/29 right now I've hacked group data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19765d9a-b45a-4c16-b83b-064d389639e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter variables\n",
    "result_prefix = \"new_model_test\"\n",
    "agent_directory = \"Agent_data/\"\n",
    "agent_file_prefix = result_prefix + \"new_model_test_Agent-\"\n",
    "group_directory = \"Group_data/\"\n",
    "group_file_prefix = result_prefix + \"new_model_test_Group-\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cfeb9c-f1e7-4be3-8738-6307894e2a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_agent_results(agent_file_prefix, time_steps):\n",
    "    agent_dfs = {}\n",
    "    for filename in os.listdir(agent_directory):\n",
    "        file_path = os.path.join(agent_directory, filename)\n",
    "        # Check if it's a regular file (not a directory)\n",
    "        if os.path.isfile(file_path):\n",
    "            temp = open(file_path, 'r')\n",
    "            temp_lines = temp.readlines()\n",
    "            num_sections = len(temp_lines)//(time_steps+1)\n",
    "            df_set = []\n",
    "            for i in range(num_sections):\n",
    "                df = pd.read_csv(file_path, skiprows = i*(time_steps+1), nrows = time_steps, comment=\"#\")\n",
    "                df_set.append(df)\n",
    "            agent_dfs[filename.strip(agent_file_prefix).strip(\".txt\")] = df_set\n",
    "    return agent_dfs\n",
    "\n",
    "def get_group_results(group_file_prefix, time_steps):\n",
    "    group_dfs = {}\n",
    "    for filename in os.listdir(group_directory):\n",
    "        file_path = os.path.join(group_directory, filename)\n",
    "        # Check if it's a regular file (not a directory)\n",
    "        if os.path.isfile(file_path):\n",
    "            temp = open(file_path, 'r')\n",
    "            temp_lines = temp.readlines()\n",
    "            num_sections = len(temp_lines)//(time_steps+1)\n",
    "            df_set = []\n",
    "            for i in range(num_sections):\n",
    "                df = pd.read_csv(file_path, skiprows = i*(time_steps+1), nrows = time_steps, comment=\"#\")\n",
    "                df_set.append(df)\n",
    "            group_dfs[filename.strip(group_file_prefix).strip(\".txt\")] = df_set\n",
    "    return group_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ef9891-6fc1-4910-8146-f6c95b24adbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_dfs = get_agent_results(agent_file_prefix, 100)\n",
    "group_dfs = get_group_results(group_file_prefix, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cf5121-6494-4031-9e1c-32cdb9de25ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# I just need the data for deviant_mean_tolerance = 0.5, actually, feeling a lil brain-dead\n",
    "# 0 = standard, 1 = deviant\n",
    "\n",
    "# group_compositions[group_id] = [[group_count], [num_standards], [num_deviants]]\n",
    "group_compositions = {}\n",
    "\n",
    "for group, dfset in group_dfs.items():\n",
    "    data_group_count = []\n",
    "    data_num_standards = []\n",
    "    data_num_deviants = []\n",
    "    for df in dfset:\n",
    "        data_group_count.append(df['group_count'].values)\n",
    "        data_num_standards.append(df['num_deviants'].values)\n",
    "        data_num_deviants.append(df['num_standards'].values)\n",
    "        group_compositions[group] = {'group_count':data_group_count, 'num_standards':data_num_standards, 'num_deviants':data_num_deviants}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0792ba9f-ab51-4bbd-8473-6031c1d165a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#show the grphs of deviant v standard counts over timesteps\n",
    "def plot_group_comps(group_dfs, figures):\n",
    "    for group, dfs in group_dfs.items():\n",
    "        time_steps = range(len(dfs['group_count'][0]))\n",
    "        \n",
    "        # Plot on specific figures for each label\n",
    "        for label, df in dfs.items():\n",
    "            for d in df[:1]:\n",
    "                # Select the specific figure corresponding to the label\n",
    "                plt.figure(figures[label].number)\n",
    "\n",
    "                # Plot the data\n",
    "                plt.plot(time_steps, d, label=f\"{group} {label}\")\n",
    "\n",
    "                # Adding labels and title\n",
    "                plt.xlabel(\"Timesteps\")\n",
    "                plt.ylabel(\"Counts\")\n",
    "                plt.title(f\"{label} per Group over Time for First Run\")\n",
    "\n",
    "                # Add legend to the plot\n",
    "                plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c821a0a-e6b9-4d36-a142-2e0ee7721300",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "figures = {'group_count': plt.figure(), 'num_deviants': plt.figure(), 'num_standards': plt.figure()}\n",
    "plot_group_comps(group_compositions, figures)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d5f912-cc05-4cee-8932-899c6378a979",
   "metadata": {},
   "source": [
    "# grabbing a representative Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa54fbcc-e78d-4c90-9394-a0cd5c30c646",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_high_agent(agent_dfs):\n",
    "    max_dicts = {}\n",
    "    num_runs = len(list(agent_dfs.values())[0])\n",
    "    for agent, data in agent_dfs.items():\n",
    "        for i in range(num_runs):\n",
    "            if i not in max_dicts:\n",
    "                max_dicts[i] = (f\"Agent with highest ending payoff = {agent}\", data[i].copy())\n",
    "            else:\n",
    "                if max_dicts[i][1].iloc[-1]['accumulated_payoff'] < data[i].iloc[-1]['accumulated_payoff']:\n",
    "                    max_dicts[i] = (f\"Agent with highest ending payoff = {agent}\", data[i].copy())\n",
    "                    print(f\"Updated highest agent during run {i} is {agent} with payoff {data[i].iloc[-1]['accumulated_payoff'].copy()}\")\n",
    "    return max_dicts\n",
    "\n",
    "def grab_low_agent(agent_dfs):\n",
    "    low_dicts = {}\n",
    "    num_runs = len(list(agent_dfs.values())[0])\n",
    "    for i in range(num_runs):\n",
    "        for agent, data in agent_dfs.items():\n",
    "            if i not in low_dicts:\n",
    "                low_dicts[i] = (f\"Agent with lowest ending payoff = {agent}\", data[i].copy())\n",
    "            else:\n",
    "                if low_dicts[i][1].iloc[-1]['accumulated_payoff'] > data[i].iloc[-1]['accumulated_payoff']:\n",
    "                    low_dicts[i] = (f\"Agent with lowest ending payoff = {agent}\", data[i].copy())\n",
    "                    print(f\"Updated lowest agent during run {i} is {agent} with payoff {data[i].iloc[-1]['accumulated_payoff'].copy()}\")\n",
    "    return low_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9bdff8b-836c-4686-b55f-2e9ec6c3e1d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_dicts = grab_high_agent(agent_dfs)\n",
    "low_dicts = grab_low_agent(agent_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae44e791-c11e-4faa-ad51-2c55c4843588",
   "metadata": {},
   "source": [
    "# plotting the representative agent against the other agents\n",
    "Need to show the representative agent stats, and how they move around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ce1215-5668-4ce3-84f2-dc504c57bb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def plot_representative(agent_dfs, rep_dict, string_param): # rep_dict = max or low_dict depending on what you want, string_param = what we looking at\n",
    "    for run, rep_data in rep_dict.items():\n",
    "        plt.figure()\n",
    "        averages = {}\n",
    "        standards = 0\n",
    "        deviants = 0\n",
    "        \n",
    "        # also going to get upper and lower bounds of tolerance, effort to compare to\n",
    "        \n",
    "        \n",
    "        for agent, data in agent_dfs.items(): # getting the other agents, and comparing\n",
    "            if agent != rep_data[0].split()[-1]:\n",
    "                if data[run].iloc[0]['type'] == 0:\n",
    "                    standards += 1\n",
    "                    if 'standard' not in averages:\n",
    "                        averages['standard'] = np.array(data[run]['accumulated_payoff'].copy())\n",
    "                    else:\n",
    "                        averages['standard'] += np.array(data[run]['accumulated_payoff'].copy())\n",
    "                elif data[run].iloc[0]['type'] == 1:\n",
    "                    deviants += 1\n",
    "                    if 'deviant' not in averages:\n",
    "                        averages['deviant'] = np.array(data[run]['accumulated_payoff'].copy())\n",
    "                    else:\n",
    "                        averages['deviant'] += np.array(data[run]['accumulated_payoff'].copy())\n",
    "            else:\n",
    "                plt.plot(data[run].index, data[run]['accumulated_payoff'].copy(), label=f\"Agent {agent}\")\n",
    "        \n",
    "        averages['standard'] = averages['standard']/standards\n",
    "        \n",
    "        averages['deviant'] = averages['deviant']/deviants\n",
    "        plt.plot(data[run].index, averages['deviant'], label=\"Average deviant payoff\")\n",
    "        plt.plot(data[run].index, averages['standard'], label=\"Average standard payoff\")\n",
    "        plt.legend()\n",
    "        plt.xlabel('Timesteps')  # Set x-axis label\n",
    "        plt.ylabel('Payoffs/Effort')  # Set y-axis label\n",
    "        plt.title(f\"Average Agent Payoffs versus Agent with {string_param} Payoff, Run: {run}\")\n",
    "        \n",
    "        # printing run parameters\n",
    "        print(f\"Run {run} Parameters:\")\n",
    "        print(f\"Deviant Mean Tolerance: {agent_dfs['1'][run].iloc[0]['deviant_mean_tolerance']}\")\n",
    "        print(\"Standard Mean Tolerance: 0.5\") # hard-coded but it shouldn't change\n",
    "        print(f\"Global Mean Effort: 1.0\") # hard-coded for now, but will update\n",
    "        \n",
    "        plt.show()\n",
    "        print(f\"Outstanding Agent {rep_data[0].split()[-1]} Run {run} Stats:\")\n",
    "        print(f\"Agent Type = {agent_dfs[rep_data[0].split()[-1]][run]['type'].iloc[0]}\")\n",
    "        print(f\"Mean Effort = {agent_dfs[rep_data[0].split()[-1]][run]['mean_value'].iloc[0]}\")\n",
    "        print(f\"Mean Tolerance = {agent_dfs[rep_data[0].split()[-1]][run]['tolerance'].iloc[0]}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8827402-344c-4ed0-a803-907af2fc4b92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_representative(agent_dfs, max_dicts, \"Highest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff825125-af8a-45b8-82aa-c2ec4ddeff4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_representative(agent_dfs, low_dicts, \"Lowest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed324931-39c5-46ad-8bb2-1389ff7735f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting number of times an agent left their group, and what time step that occurred\n",
    "def get_group_change(agent_df): # singular agent df input\n",
    "    group_change_tracker = {}\n",
    "    last_group = -1\n",
    "    for i, row in agent_df.iterrows():\n",
    "        if i == 0:\n",
    "            last_group = row['group_id'].copy()\n",
    "        if row['group_id'] != last_group:\n",
    "            group_change_tracker[i] = row['group_id'].copy()\n",
    "            last_group = row['group_id'].copy()\n",
    "    return group_change_tracker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a0e825-0e8c-4a7a-ba35-b5f0393a881c",
   "metadata": {},
   "source": [
    "Creating a divorce dict, with all divorces that occurs during each run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb6ef5c-2f81-40fc-9d28-b16bd5189ba9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "divorce_dict = {}\n",
    "\n",
    "for agent, data in agent_dfs.items():\n",
    "    for run, run_data in enumerate(data):\n",
    "        woo = get_group_change(run_data)\n",
    "        if woo:\n",
    "            if run not in divorce_dict:\n",
    "                divorce_dict[run] = {}\n",
    "            divorce_dict[run][agent] = woo\n",
    "            print(f\"Change in Agent {agent} during Run {run}\")\n",
    "            print(woo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14930594-87e9-4f8c-b780-6b28d26369cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the agent payoffs relative to prior steps\n",
    "import numpy as np\n",
    "\n",
    "# also going to add divorce time for the agent of interest\n",
    "\n",
    "def relative_representative(agent_dfs, rep_dict, string_param, divorce_dict = None): # rep_dict = max or low_dict depending on what you want, string_param = what we looking at\n",
    "    for run, rep_data in rep_dict.items():\n",
    "        plt.figure()\n",
    "        averages = {}\n",
    "        standards = 0\n",
    "        deviants = 0\n",
    "        \n",
    "        # also going to get upper and lower bounds of tolerance, effort to compare to\n",
    "        \n",
    "        \n",
    "        for agent, data in agent_dfs.items(): # getting the other agents, and comparing\n",
    "            if agent != rep_data[0].split()[-1]:\n",
    "                if data[run].iloc[0]['type'] == 0:\n",
    "                    standards += 1\n",
    "                    if 'standard' not in averages:\n",
    "                        averages['standard'] = np.array(data[run]['accumulated_payoff'].copy())\n",
    "                    else:\n",
    "                        averages['standard'] += np.array(data[run]['accumulated_payoff'].copy())\n",
    "                elif data[run].iloc[0]['type'] == 1:\n",
    "                    deviants += 1\n",
    "                    if 'deviant' not in averages:\n",
    "                        averages['deviant'] = np.array(data[run]['accumulated_payoff'].copy())\n",
    "                    else:\n",
    "                        averages['deviant'] += np.array(data[run]['accumulated_payoff'].copy())\n",
    "            else:\n",
    "                agent_shift = data[run]['accumulated_payoff'][1:].copy().tolist()\n",
    "                \n",
    "                relatives = [agent_shift[i] - data[run]['accumulated_payoff'][i].copy() for i in range(len(data[run]['accumulated_payoff']) - 1)]\n",
    "                \n",
    "                plt.plot(data[run].index[:-1], relatives, label=f\"Agent {agent}\")\n",
    "                \n",
    "                 #  if we have a divorce dict, then add the point at which the agent divorces\n",
    "                if divorce_dict:\n",
    "                    check = rep_data[0].split()[-1]\n",
    "                    if check in divorce_dict[run]:\n",
    "                        print(\"hi!\")\n",
    "                        print(divorce_dict[run][check])\n",
    "                        plt.scatter(list(divorce_dict[run][check].keys())[0], relatives[int(list(divorce_dict[run][check].keys())[0])], s=50, zorder=5, color='black')\n",
    "                        plt.text( list(divorce_dict[run][check].keys())[0], relatives[int(list(divorce_dict[run][check].keys())[0])], f\"Agent {agent} divorce\", fontsize=6, color='black', ha='right')\n",
    "                    else:\n",
    "                        print(\"Outstanding agent did not divorce.\")\n",
    "        averages['standard'] = averages['standard']/standards\n",
    "        averages['deviant'] = averages['deviant']/deviants\n",
    "        \n",
    "        relative = {}\n",
    "        \n",
    "        shift = averages['standard'][1:].tolist()\n",
    "        \n",
    "        relative['standard'] = [shift[i] - averages['standard'][i]  for i in range(len(averages['standard']) - 1)]\n",
    "        \n",
    "        shift = averages['deviant'][1:].tolist()\n",
    "        relative['deviant'] = [shift[i] - averages['deviant'][i] for i in range(len(averages['deviant']) - 1)]\n",
    "        \n",
    "        plt.plot(data[run].index[:-1], relative['deviant'], label=\"Relative Average deviant payoff\")\n",
    "        plt.plot(data[run].index[:-1], relative['standard'], label=\"Relative Average standard payoff\")\n",
    "        plt.legend()\n",
    "        plt.xlabel('Timesteps')  # Set x-axis label\n",
    "        plt.ylabel('Relative Payoffs/Effort')  # Set y-axis label\n",
    "        plt.title(f\"Average Agent Payoffs versus Agent with {string_param} Payoff, Relative to Prior Step, Run: {run}\")\n",
    "        \n",
    "        # printing run parameters\n",
    "        print(f\"Run {run} Parameters:\")\n",
    "        print(f\"Deviant Mean Tolerance: {agent_dfs['1'][run].iloc[0]['deviant_mean_tolerance']}\")\n",
    "        print(f\"Standard Mean Tolerance: {parameter_dict['mean_tolerance'][0]}\") # hard-coded but it shouldn't change\n",
    "        print(f\"Global Mean Effort: {parameter_dict['mean_value'][0]}\") # hard-coded for now, but will update\n",
    "        \n",
    "        plt.show()\n",
    "        print(f\"Outstanding Agent {rep_data[0].split()[-1]} Run {run} Stats:\")\n",
    "        print(f\"Agent Type = {agent_dfs[rep_data[0].split()[-1]][run]['type'].iloc[0]}\")\n",
    "        print(f\"Mean Effort = {agent_dfs[rep_data[0].split()[-1]][run]['mean_value'].iloc[0]}\")\n",
    "        print(f\"Mean Tolerance = {agent_dfs[rep_data[0].split()[-1]][run]['tolerance'].iloc[0]}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2a1f6d-6507-428e-931d-2c2a8028dbb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "relative_representative(agent_dfs, low_dicts, \"Lowest\", divorce_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d559d03-beb4-4915-8e0d-e200c85d27e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "relative_representative(agent_dfs, max_dicts, \"Highest\", divorce_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bd102c-c032-4962-a1b7-0bbb361c8081",
   "metadata": {},
   "source": [
    "# Low effort agent search\n",
    "Find the agents that are \"social loafers\", by checking agent mean_values and picking out those below 2.5 std dev away from the global mean_values\n",
    "\n",
    "Issue of interpretatation here though; are we modeling average effort or social-loafing? I.e., if an agent just happens to contribute less, it means that they contribute less in general; it is not specific to social-loafing. We would need to describe a social-loafin type agent, with unique behavior when they are in a group, vs when they are alone.\n",
    "\n",
    "Not enough agents 2.5 std away, sample size too small, set to 2 std dev away"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2a08e9-e0cd-4e95-9f18-df546f388597",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_loafers(agent_dfs, mean_value, std_value):\n",
    "    lower = mean_value - (2 * std_value)\n",
    "    print(lower)\n",
    "    loafers = {} # loafers [run #] = agent[]\n",
    "    \n",
    "    lowest = 100\n",
    "    \n",
    "    for agent, data_dfs in agent_dfs.items():\n",
    "        for run, data in enumerate(data_dfs):\n",
    "            if data.iloc[0]['mean_value'] < lowest:\n",
    "                lowest = data.iloc[0]['mean_value']\n",
    "                print(lowest)\n",
    "            if data.iloc[0]['mean_value'] < lower:\n",
    "                print(\"got one\")\n",
    "                print(data.iloc[0]['mean_value'])\n",
    "                if run not in loafers:\n",
    "                    loafers[run] = [agent]\n",
    "                else:\n",
    "                    loafers[run].append(agent)\n",
    "    return loafers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b65f5eb-0492-49f1-9c1c-e63cb811d5cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loafers = find_loafers(agent_dfs, mean_value = float(parameter_dict['mean_value'][0]), std_value = float(parameter_dict['std_value'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c92b94d-6417-4fa0-a208-c9474bead035",
   "metadata": {},
   "outputs": [],
   "source": [
    "for run, agents in list(loafers.items()):\n",
    "    print(run)\n",
    "    print(agents)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7541a6-1aed-4eb5-bcbf-99e7fa084bee",
   "metadata": {},
   "source": [
    "# Now we have the loafing agents, now what?\n",
    "Once we've found social loafing agents, what can that tell us about other agent interactions with them? Check their group, and see what happened the agents in their group.\n",
    "\n",
    "Expectation: All other agents should leave, and they should see an increase in payoff rate after divorce. The loafing agent should see a decrease in payoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a081d6b-72fd-4ef2-8f5f-d7f6bafdeed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "\n",
    "# grabbing the group the loafing agent is in, and printing the graphs for each agent with labels\n",
    "def loafer_representation(agent_dfs, loafer_id, run, divorce_dict):\n",
    "    loafer_group = agent_dfs[loafer_id][run].iloc[0]['group_id'] # group they started \n",
    "    \n",
    "    unfortunate_souls = []\n",
    "    \n",
    "    for agent_id, dfs in agent_dfs.items():\n",
    "        if dfs[run].iloc[0]['group_id'] == loafer_group and agent_id != loafer_id:\n",
    "            unfortunate_souls.append(agent_id)\n",
    "    \n",
    "    print(f\"Prithee tell me, what became of those unfortunate souls with agent {loafer_id} in run {run}?\")\n",
    "    \n",
    "    # Showing the relative results for loafer agent\n",
    "    loafer_shift = agent_dfs[loafer_id][run]['accumulated_payoff'][1:].copy().tolist()\n",
    "                \n",
    "    relatives = [loafer_shift[i] - agent_dfs[loafer_id][run]['accumulated_payoff'][i].copy() for i in range(len(agent_dfs[loafer_id][run]['accumulated_payoff']) - 1)]\n",
    "                \n",
    "    plt.plot(agent_dfs[loafer_id][run].index[:-1], relatives, label=f\"Agent {loafer_id}\")\n",
    "    \n",
    "    # going through the unfortunate souls and plotting their stuff on the same graph\n",
    "    for us in unfortunate_souls:\n",
    "        us_shift = agent_dfs[us][run]['accumulated_payoff'][1:].copy().tolist()\n",
    "                \n",
    "        relatives = [us_shift[i] - agent_dfs[us][run]['accumulated_payoff'][i].copy() for i in range(len(agent_dfs[us][run]['accumulated_payoff']) - 1)]\n",
    "        \n",
    "        plt.plot(agent_dfs[loafer_id][run].index[:-1], relatives, label=f\"Agent {us}\")\n",
    "        \n",
    "        last_breakpoint = 0\n",
    "        \n",
    "        if us in divorce_dict[run]:\n",
    "            plt.scatter(list(divorce_dict[run][us].keys())[0], relatives[int(list(divorce_dict[run][us].keys())[0])], s=50, zorder=5, color='black')\n",
    "            plt.text( list(divorce_dict[run][us].keys())[0], relatives[int(list(divorce_dict[run][us].keys())[0])], f\"Agent {us} divorce\", fontsize=6, color='black', ha='right')\n",
    "            \n",
    "            for i, breakpoint in enumerate(list(divorce_dict[run][us].keys()) + [agent_dfs[us][run].index[-1]]):\n",
    "                # create some lines of best fits bounded by divorce points\n",
    "                coefficients = np.polyfit(agent_dfs[us][run].index[last_breakpoint:breakpoint], relatives[last_breakpoint:breakpoint], 1)\n",
    "                poly = np.poly1d(coefficients)\n",
    "                y_fit = poly(agent_dfs[us][run].index[last_breakpoint:breakpoint])\n",
    "                plt.plot(agent_dfs[us][run].index[last_breakpoint:breakpoint], y_fit, label=f\"Agent {us}, segment{i}\")\n",
    "                last_breakpoint = breakpoint\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.xlabel('Timesteps')  # Set x-axis label\n",
    "    plt.ylabel('Relative Payoffs/Effort')  # Set y-axis label\n",
    "    plt.title(f\"Monsier ou Madame Loafer {loafer_id} avec sa amis\")\n",
    "    figure(figsize=(10, 12), dpi=120)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f1f413-7bfc-440e-976e-2264dfad7221",
   "metadata": {},
   "outputs": [],
   "source": [
    "loafer_representation(agent_dfs, '35', 11, divorce_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e358f11-4c39-4e0a-8507-c460ed5e1290",
   "metadata": {},
   "outputs": [],
   "source": [
    "loafer_representation(agent_dfs, '35', 6, divorce_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43741db1-1a63-4dbb-aa2c-f50820035b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loafer_representation(agent_dfs, '35', 1, divorce_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1251b402-a737-409c-b63e-32272639d273",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
